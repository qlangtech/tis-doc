---
slug: datapipe-ai-agent-practice
title: 国产首个大数据 AI Agent 诞生记：让数据管道"说人话"
authors: [baisui]
tags: [AI Agent, 数据集成, TIS, DeepSeek, 通义千问]
date: 2025-11-20
draft: true
---

# 国产首个大数据 AI Agent 诞生记：让数据管道"说人话"

## 一个工程师的执念

做了这么多年大数据集成，我一直有个执念：**能不能让数据管道的构建像聊天一样简单？**

传统的数据管道搭建，即便是用了 TIS 这样的可视化平台，仍然需要：
- 理解复杂的数据源配置参数
- 在多个页面间反复跳转
- 手动选择插件、填写表单
- 记住各种端点类型和配置规范

一个简单的 MySQL 到 Doris 的同步任务，熟练工程师至少需要 15-20 分钟。新手？可能要折腾大半天。

{/* 插图位置1：传统数据管道配置界面截图 - 展示多个配置页面、复杂表单的画面，突出繁琐性 */}

## 转机：基于领域模型的 AI Agent

今年，我们做了一件让自己都感到兴奋的事情：**在 TIS 中手搓了国内首个大数据领域的原生 AI Agent**。

没有用 dify，没有用 n8n，更没有套用通用的 AI 框架。

为什么？因为我们有更好的基础——**TIS 经过多年积累沉淀下来的领域模型**。

这套模型包括：
- 完整的数据源插件体系（MySQL、PostgreSQL、SqlServer...）
- 标准化的 Reader/Writer 扩展点
- 成熟的批流一体架构（DataX + Flink-CDC）
- 借鉴 Jenkins 的强大 SPI 机制

有了这些，我们才敢说：**这是深度整合、开箱即用的 AI Agent**。

## 对比：从 20 分钟到 2 分钟

让我们看一个真实场景：**将 MySQL 数据库同步到 Apache Doris**

### 传统方式（约 15-20 分钟）

1. 登录 TIS 控制台
2. 进入数据源管理，创建 MySQL 数据源
   - 填写主机地址、端口、用户名、密码
   - 填写数据库名称
   - 测试连接
3. 创建 Doris 数据源
   - 配置 FE 地址、端口
   - 配置认证信息
4. 创建数据管道
   - 选择源端 MySQL Reader 插件
   - 关联刚才创建的 MySQL 数据源
   - 配置读取参数（splitPk、fetchSize...）
5. 配置目标端
   - 选择 Doris Writer 插件
   - 关联 Doris 数据源
   - 配置写入参数
6. 选择需要同步的表
7. 配置字段映射
8. 决定是否启动增量同步
   - 如果需要，还要配置 Flink-CDC
   - 配置 binlog 监听参数
9. 保存配置，手动触发执行

{/* 插图位置2：传统方式流程图 - 用流程图展示9个步骤，用不同颜色标注繁琐步骤 */}

### AI Agent 方式（约 2 分钟）

打开 TIS，点击 AI Agent 对话框，输入：

```
我需要创建一个数据同步管道，从 MySQL 同步到 Doris 数据库。
MySQL 数据源：用户名 root，密码 123456，主机 192.168.28.200，端口 3306，数据库名称 order_db
Doris 数据源：FE 地址 192.168.28.201，端口 8030，用户名 admin，密码 admin123
同步 order_db 中的所有表，管道创建完成后自动触发历史数据同步，并开启增量同步。
```

**然后，喝口咖啡，看着 AI Agent 自动完成：**

1. ✅ 解析你的需求
2. ✅ 生成执行计划（Plan-and-Execute 模式）
3. ✅ 检查并下载所需插件
4. ✅ 创建 MySQL 数据源配置
5. ✅ 创建 Doris 数据源配置
6. ✅ 创建 MySQL Reader
7. ✅ 创建 Doris Writer
8. ✅ 选择同步表
9. ✅ 触发历史数据同步
10. ✅ 配置并启动 Flink-CDC 增量通道

整个过程，**你只需要用自然语言描述需求，剩下的交给 AI**。

{/* 插图位置3：AI Agent 对话界面截图 - 展示实际的对话过程，带有打字机效果的消息流 */}

## 技术实现：手搓的艺术

很多人问："为什么不用 dify 或 n8n？"

答案很简单：**通用框架无法理解 TIS 的领域模型**。

我们的实现方案：

### 1. 深度整合的插件系统

AI Agent 直接调用 TIS 的插件描述接口：

```java
DescriptorsJSONForAIPromote.desc("com.qlangtech.tis.plugin.datax.DataxMySQLReader")
```

返回的 JSON 不仅包含插件参数，还包括：
- 字段类型、默认值、必填项
- 参数之间的依赖关系
- 插件的扩展点信息
- 嵌套插件的描述

这些信息作为 Prompt 提交给大模型（DeepSeek / 通义千问），让 AI 真正"理解"TIS 的插件体系。

### 2. Plan-and-Execute 架构

借鉴 LangChain 的思想，但完全自主实现：

- **Plan 阶段**：AI 解析用户意图，生成结构化的执行计划
- **Execute 阶段**：逐步执行计划中的每个任务
- **Feedback 循环**：如果缺少必要参数，主动询问用户

### 3. SSE 实时反馈

使用 Server-Sent Events 实现：
- 打字机效果的消息推送
- 实时显示执行进度
- Token 消耗统计
- LLM 加载状态展示

### 4. 智能错误处理

- 任务可随时取消
- 自动错误恢复
- 缺失参数智能补全

## 真实体验：对话式数据集成

使用 TIS AI Agent 的感觉，就像和一个资深的数据工程师对话：

**你**："帮我把 MySQL 的订单表同步到 Paimon。"

**AI Agent**："好的，我需要一些信息。MySQL 的连接地址是？"

**你**："192.168.28.200，用户名 root，密码 123456。"

**AI Agent**："收到。Paimon 使用的 Hive Metastore 地址是？"

**你**："192.168.28.200，数据库名称 default。"

**AI Agent**："明白了。正在为您创建管道...
✅ MySQL 数据源已创建
✅ Paimon Writer 已配置
✅ 检测到订单表有 15 个字段，已自动映射
需要启动增量同步吗？"

**你**："需要。"

**AI Agent**："好的，正在配置 Flink-CDC...
✅ 历史数据同步已触发
✅ 增量通道已启动
全部完成！您可以在控制台查看同步状态。"

{/* 插图位置4：对话式交互示例 - 类似聊天软件的对话气泡，展示人机交互的自然流畅 */}

## 未来：通用型数据智能体的畅想

当前的 TIS AI Agent 专注于数据管道创建，但这只是开始。

基于我们正在实施的**通用化架构改进方案**，未来的 TIS AI Agent 将成为**数据集成领域的全能智能体**。

### 技术路径：从"场景枚举"到"能力组合"

我们正在构建一个三层抽象模型：

```
PluginCapability（插件能力） - 物理层：TIS 的实际插件
        ↓ 封装为
AtomicCapability（原子能力） - 逻辑层：可组合的逻辑单元
        ↓ 组合成
CompositeCapability（复合能力） - 业务层：完整的业务功能
```

**核心思想**：不再枚举所有可能的用户场景，而是将 TIS 的功能分解为可组合的**原子能力**，通过 AI 动态组合来满足千变万化的需求。

{/* 插图位置5：三层抽象模型架构图 - 展示 PluginCapability → AtomicCapability → CompositeCapability 的层次关系 */}

### 能力地图（Roadmap）

#### 第一阶段（已完成）：数据管道构建 ✅
- ✅ 端到端批量同步
- ✅ 实时增量同步
- ✅ 多数据源支持

#### 第二阶段（开发中）：数据质量管理 🚧

想象一下这样的对话：

**你**："检查一下订单表的数据质量，看看有没有异常。"

**AI Agent** 自动：
- 分析表结构和业务语义
- 生成数据质量检测规则
- 执行质量扫描
- 生成质量报告
- 发现问题后主动建议修复方案

**技术实现**：
- 原子能力：数据 profiling、规则引擎、异常检测
- 组合模式：质量扫描 = 数据抽取 + 规则匹配 + 结果汇总

#### 第三阶段（规划中）：数据血缘分析 🔮

**你**："这个字段的数据来源是哪里？"

**AI Agent**：
- 自动追溯数据血缘关系
- 生成可视化血缘图谱
- 分析影响范围

**技术实现**：
- 基于 TIS 的元数据管理
- 结合 SQL 解析能力
- 自动构建血缘 DAG

#### 第四阶段（愿景）：智能运维助手 💡

**场景 1：性能优化**

**你**："这个同步任务跑得太慢了。"

**AI Agent**：
- 分析执行日志和性能指标
- 识别瓶颈（网络、IO、计算）
- 自动调优参数（fetchSize、并发度）
- 甚至建议更换更高效的插件实现

**场景 2：故障诊断**

**你**："增量同步中断了。"

**AI Agent**：
- 分析错误堆栈
- 检查数据源连通性
- 验证权限配置
- 提供分步修复方案

**场景 3：实时分析**

**你**："监控 Kafka 流量，如果检测到刷单行为立即告警。"

**AI Agent**：
- 创建 Kafka Consumer
- 配置刷单检测规则（基于频率、金额、时间窗口）
- 设置告警通道（钉钉、飞书、邮件）
- 启动实时监控任务

**技术实现**：
- 动态组合多个原子能力
- 能力图谱（Capability Graph）自动编排
- 支持并行执行和依赖管理

{/* 插图位置6：能力组合示意图 - 展示多个原子能力如何组合成复合能力，用流程图或拓扑图表示 */}

### 为什么这能实现？

**1. 强大的领域模型基础**

TIS 的插件体系本身就是高度抽象和标准化的，每个插件都有清晰的：
- 输入输出规范
- 配置参数描述
- 前置后置条件

这为 AI 理解和组合能力提供了天然优势。

**2. 能力组合器（Capability Composer）**

我们正在开发的智能组合器能够：
- 根据用户意图识别所需的原子能力
- 检查能力间的兼容性和依赖关系
- 自动选择最优的插件实现
- 生成可执行的任务计划（TaskPlan）

**3. 开放的 LLM 接口**

支持切换不同的大模型（DeepSeek、通义千问、GPT-4...），利用最新的 AI 能力：
- 更好的语义理解
- 更强的推理能力
- 更准确的意图识别

## 加入我们，一起改变数据集成的未来

TIS AI Agent 不是一个 Demo，而是一个**已经在生产环境稳定运行的工具**。

**它代表了我们对数据集成未来的思考：**
- 技术应该服务于人，而不是让人适应技术
- AI 不是噱头，而是真正降低专业门槛的工具
- 开源精神 + 领域深耕 = 真正有价值的创新

**现在就试用 TIS AI Agent：**
- GitHub：[https://github.com/datavane/tis](https://github.com/datavane/tis)
- 官方文档：[https://tis.pub/docs](https://tis.pub/docs)

让数据管道"说人话"，从今天开始。

---

**关于 TIS**

TIS（T-Insert-Search）是一个企业级数据集成服务平台，基于批流一体化架构，提供简单易用的操作界面来降低端到端数据同步的实施门槛。项目完全开源，支持 MySQL、PostgreSQL、Oracle、SqlServer、MongoDB、Elasticsearch、ClickHouse、Doris、StarRocks、Paimon 等数十种数据源。
