---
title: 与DolphinScheduler集成
date: 2020-07-26
type: book
weight : 10
---
import Figure from '/src/components/Figure';
import Link from '/src/components/Link';
import CodeBlock from '@theme/CodeBlock';
import BZhan from '/src/components/BZhan';

## 背景

TIS经过前几个版本迭代、发布，获得了社区用户认可，在TIS平台中轻点几下鼠标便可快速构建一个批量/实时同步数据管道，确实非常方便。

与此同时，有不少用户反馈，如果库中的表比较多，如何能突破TIS单机版单次导入有40张表的限制， 以及何时能提供`报警`、`定时任务`等功能。用户反馈的问题确实是现在TIS的短板，不尽想起了开源大数据领域的一款神器`DolphinScheduler`（以下简称DS），它是企业级构建ELT数仓的必备工具，
在DS中有完备的工作流上下线安全保证、任务失败报警、定时任务触发、可视化DAG、可控资源组、弹性Worker扩展，非常完备。

唯独在DS中的不足是，在DS配置数据采集任务需要添加`DataX`或者`SeaTunnel`节点，用户需要手写基于`JSON`的配置脚本，这对一个即使是有数年工作经验的开发工程师而言也会觉得非常烦冗且容易出错，而这正好是TIS的拿手好戏。

<Figure img={require('./images/ds_datax.jpeg')} />

TIS和DS存在优势互补，本着避免重复造轮子的原则，在TIS V4.0.1 版本需求调研阶段就开始考虑如何让TIS整合到DS中（ [https://github.com/datavane/tis/issues/345](https://github.com/datavane/tis/issues/345) ）

## 助力`DS`构建ETL数仓

整合方案的基本思路是，把TIS作为一个任务配置元数据服务节点，可以将配置完成的数据管道一键同步到DS中，后续数据集成任务的执行，全部在DS系统中完成。

当DS中需要开始执行数据集成任务时候，会通过任务名称 从TIS调取执行任务所需要的配置文件及Jar包文件。后续同步任务执行，使用DS的Worker节点，完全与TIS系统没有关系了，这样的好处是TIS不负责同步任务执行，就可以以最小的资源配置部署，推荐是以docker容器启动即可。

以下是对应的执行流程：
<Figure img={require('./images/ds_tis_corporate.png')} />

以上第4步`反馈实时日志、执行状态`是可选的，用户如需要查看DS执行的同步任务的执行具体的执行状态，例如，某表当前实时同步记录数等信息，可以在第1步，推送任务设置的表单中勾选相应的选项。

## 视频讲解

 <BZhan bvid="BV1wGyhYGEU1" />

## 与DS整合具体步骤

### 1. 安装TIS并且最配一个数据管道

熟悉TIS的老用户应该对此步骤非常熟悉，可直接跳过。刚接触TIS的用户可跳转到以下链接中，完成此步骤：
1. <Link href={require("@site/docs/install/tis/index.mdx")} >安装TIS</Link> 
2. [安装TIS视频教程](https://www.bilibili.com/video/BV1QT41147AT)
3. 构建一个批量数据通道 <Link href={require("@site/docs/example/mysql-sync-doris/index.mdx")} anchor="step3-构建批量数据管道">参照MySQL同步Doris</Link> 

### 2. DS中作初始化配置

export const ReplaceShell = () => {
return (
<div>
<CodeBlock language="shell">
 DATASYNC_FILE="$(find ./libs  -name  dolphinscheduler-task-datasync-*.jar)" && wget -O $DATASYNC_FILE  http://mvn-repo.oss-cn-hangzhou.aliyuncs.com/release/com/qlangtech/tis/plugins/dolphinscheduler-task-tis-datasync/{metadata.version}/dolphinscheduler-task-tis-datasync-{metadata.version}-shaded.jar
</CodeBlock>
</div>
);
}

1. 安装DS [下载地址](https://dolphinscheduler.apache.org/en-us/download)

    :::info DolphinScheduler 版本要求
    与TIS 整合的DolphinScheduler需要使用 **3.2.2**以上版本
    :::

2. 进入 DS Home目录

   ``` shell
   cd $DS_HOME
   ```

3. 执行脚本，替换DS `dolphinscheduler-task-datasync`插件实现

   :::caution 注意
   在执行以下脚本之前，需要确认DS datasync类型的节点类型没有使用，由于TIS会将该节点类型的jar包任务替换掉，如原DS中使用了该类型（datasync）的任务节点会遭到破坏。
   :::

    <ReplaceShell/>

4. 重启DS
   ```shell
   ./bin/dolphinscheduler-daemon.sh stop standalone-server
   ./bin/dolphinscheduler-daemon.sh start standalone-server
   ```

### 3. 将TIS中的任务推送到DS中

以下是对操作流程进行说明：

| 说明                                                             | 图示  |
|----------------------------------------------------------------|-----|
 | 首次使用，需要安装相应插件，在**管理**页面点击右侧图示下拉列表中的**添加**按钮                    | <Figure img={require('./images/click_add_syn_ds_plugin.png')} /> |
 | 插件选择页面选中`tis-datax-dolphinscheduler-plugin`插件，点击**安装**按钮开始安装插件 | <Figure img={require('./images/click_install_ds_plugin.png')} /> |
 | 安装完插件发现之前的下拉列表中多了一个选项`Export To Dolphinscheduler`  ，点击它        | <Figure img={require('./images/open_ds_plugin.png')} />        |
 | 打开 `Export To Dolphinscheduler`插件设置页面，该页面设置项比较多，下面详细说明 <Link href={require("@site/docs/integrations/assist/Dolphinscheduler/index.mdx")} anchor='export-to-dolphinscheduler' >详细说明</Link><br/>        | <Figure img={require('./images/set_ds_plugin.png')} />         |

下面就`Export To Dolphinscheduler`插件设置页面的设置项进行说明:

|输入项|说明|
|-|-|
|工作流名称|对应的DS中工作流名称，确保同一项目下工作流名称唯一，不能重复|
|endpoint|DS中对应的连接端配置|
|projectCode|DS中对应的项目编码|
|createHistory|DS执过程中，是否在TIS端生成执行历史记录？选择是，用户可查看DS执行的同步任务的执行具体的执行状态|
|TIS端回调|对应的DS中工作流执行过程中需要回调TIS，设置相应参数，需要确保DS端能够访问该回调地址|
|目标 |选择需要同步到DS的表|
|部署目录|TIS数据管道任务执行会在DS所在节点机器部署TIS运行所依赖的工程包，默认自动部署在DS $HOME目录|
|描述 |同步到DS的工作流名称描述|
|资源组 |对应DS中任务组概念，用以来控制工作流中的job并发数目，可以有效防止由于大量同步任务并发执行导致业务数据库过载|

下面就添加endpoint页面的设置项进行说明:

|说明|图示|
|-|-|
|点击`添加`按钮打开添加 DS endpoint页面|<Figure img={require('./images/click_add_endpoint_btn.png')} /> |
|现在可以编辑`DS endpoint`的输入项了 <Link href={require("@site/docs/integrations/assist/Dolphinscheduler/index.mdx")} anchor='ds-endpoint' >详细说明</Link>|<Figure img={require('./images/set_endpoint.png')} />|

下面就`DS endpoint`插件页面的设置项进行说明:
1. **name** ：   设置一个有意义的名称即可
2. **serverPath**：DS 访问地址的Root Context 访问地址
3. **serverToken**：DS 的 REST API 访问令牌，获取令牌的方法如下图所示：
   <Figure img={require('./images/get_security_token.png')} />

最终，填写完`Export To Dolphinscheduler`表单所需要的所有输入项之后：

|说明|图示|
|-|-|
|点击**执行**按钮就能将TIS数据管道内的数据表同步任务一键推送到DS中|<Figure img={require('./images/start_push_jobs_2_ds.png')} />|
|接下来打开DS端对应的工作流页面，发现TIS数据管道的表同步任务已经都推送成功了。<br/><br/>接下来可以将该工作流设置成上限状态，点击**运行**按钮就可以触发数据同步任务了|<Figure img={require('./images/jobs_push_success.png')} />|

### 4. 数据管道任务维护

后期如果业务系统中加表，表加字段，或者去掉某业务表，需要更新现有数据管道的脚本。当更新完毕后，可以从TIS端重新将新的数据管道推送到DS中

|说明|图示|
|-|-|
|点击按钮打开`Export To Dolphinscheduler`维护页面|<Figure img={require('./images/start_repush_jobs.png')} />|
|点击**更新**按钮重新将数据管道任务推送到DS端<br/><br/> 如果该数据管道废弃了，可以点击**删除**按钮进行删除|<Figure img={require('./images/start_repush_jobs_2.png')} />|

## 总结

以上对TIS与DS的整合方案进行了详细的介绍，并且附上了视频说明，有需要的同学可以在测试环境中尝试，欢迎反馈问题或者建议。

