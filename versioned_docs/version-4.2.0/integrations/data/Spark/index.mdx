---
title: Spark
date: 2025-03-12
type: book
sidebar_position: 1
---

import Link from '/src/components/Link';
import Figure from '/src/components/Figure';
import BZhan from '/src/components/BZhan';
import PluginFields from '/src/components/PluginFields';

## 数据端配置

<Figure img={require('./params-cfg.png')}/>

* **配置项说明:** 

<PluginFields>

1. name
	* **类型:** 单行文本
	* **必须:** 是
2. 连接方式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 

		客户端连接Spark服务端可选择以下连接方式之一：
		
		* [Amazon EC2](https://github.com/amplab/spark-ec2): scripts that let you launch a cluster on EC2 in about 5 minutes
		* [Standalone Deploy Mode](https://spark.apache.org/docs/2.4.4/spark-standalone.html): launch a standalone cluster quickly without a third-party cluster manager
		* [Mesos](https://spark.apache.org/docs/2.4.4/running-on-mesos.html): deploy a private cluster using Apache Mesos
		* [YARN](https://spark.apache.org/docs/2.4.4/running-on-yarn.html): deploy Spark on top of Hadoop NextGen (YARN)
		* [Kubernetes](https://spark.apache.org/docs/2.4.4/running-on-kubernetes.html#cluster-mode): deploy Spark on top of Kubernetes
		
		例如，选择**Standalone Deploy Mode**模式模式，可设置：`spark://192.168.28.201:7077`

	* **可选项说明:** 可选`Standalone`,`Yarn`以下是详细说明：
		* Standalone

			<Figure img={require('./params-cfg_connStrategy_Standalone.png')}/>

			* **配置项说明:** 

			1. master

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** 无
				* **说明:** 		无

		* Yarn

			<Figure img={require('./params-cfg_connStrategy_Yarn.png')}/>

			* **配置项说明:** 

			1. yarnSite

				* **类型:** 富文本
				* **必须:** 是
				* **默认值:** com.qlangtech.tis.config.spark.impl.YarnConnStrategy.dftYarnSiteContent()
				* **说明:** 

					```xml
					<?xml version="1.0"?>
					<configuration>
					 <!-- Site specific YARN configuration properties -->
					  <!--RM的主机名 -->
					  <property>
					    <name>yarn.resourcemanager.hostname</name>
					    <value>192.168.28.200</value>
					  </property>

					  <!--RM对客户端暴露的地址,客户端通过该地址向RM提交应用程序、杀死应用程序等-->
					  <property>
					    <name>yarn.resourcemanager.address</name>
					    <value>${yarn.resourcemanager.hostname}:8032</value>
					  </property>

					  <!--RM对AM暴露的访问地址,AM通过该地址向RM申请资源、释放资源等-->
					  <property>
					    <name>yarn.resourcemanager.scheduler.address</name>
					    <value>${yarn.resourcemanager.hostname}:8030</value>
					  </property>

					  <!--RM对外暴露的web http地址,用户可通过该地址在浏览器中查看集群信息-->
					  <property>
					    <name>yarn.resourcemanager.webapp.address</name>
					    <value>${yarn.resourcemanager.hostname}:8088</value>
					  </property>

					  <!--RM对NM暴露地址,NM通过该地址向RM汇报心跳、领取任务等-->
					  <property>
					    <name>yarn.resourcemanager.resource-tracker.address</name>
					    <value>${yarn.resourcemanager.hostname}:8031</value>
					  </property>

					  <!--RM对管理员暴露的访问地址,管理员通过该地址向RM发送管理命令等-->
					  <property>
					    <name>yarn.resourcemanager.admin.address</name>
					    <value>${yarn.resourcemanager.hostname}:8033</value>
					  </property>
					</configuration>
					```


</PluginFields>

## 批量写

<Figure img={require('./dataxWriter.png')}/>

* **配置项说明:** 

<PluginFields>

1. hiveserver2

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. 分区时间戳格式

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** yyyyMMddHHmmss
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为'pt'格式为开始导入数据的当前时间戳，格式为`yyyyMMddHHmmss`或者`yyyyMMdd`

3. fsName

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000

4. 分区保留数

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2
	* **说明:** 

		每进行一次DataX导入在Hive表中会生成一个新的分区，现在系统分区名称为`pt`格式为开始导入数据的时间戳

5. 自动建表

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** on
	* **说明:** 		解析Reader的元数据，自动生成Writer create table DDL语句

	* **可选项说明:** 可选`off`,`on`以下是详细说明：
		* off

			<Figure img={require('./dataxWriter_autoCreateTable_off.png')}/>

			* **配置项说明:** 

			1. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

		* on

			<Figure img={require('./dataxWriter_autoCreateTable_on.png')}/>

			* **配置项说明:** 

			1. 添加列注释

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** on
				* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

			2. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

6. fileType

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** TEXT
	* **说明:** 		描述：文件的类型，目前只支持用户配置为"text"

	* **可选项说明:** 可选`ORC`,`PARQUET`,`TEXT`以下是详细说明：
		* ORC

		* PARQUET

		* TEXT

			<Figure img={require('./dataxWriter_fileType_TEXT.png')}/>

			* **配置项说明:** 

			1. 列分割符

				* **类型:** 单选
				* **必须:** 是
				* **默认值:** char001
				* **说明:** 		描述：读取的字段分隔符，可以用'\t','\001'等字符 

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXHiveWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误

8. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** append
	* **说明:** 

		hdfswriter写入前数据清理处理模式：
		
		- **append**: 写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突，
		- **nonConflict**：如果目录下有fileName前缀的文件，直接报错

9. encoding

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** utf-8
	* **说明:** 		描述：写文件的编码配置。


</PluginFields>



