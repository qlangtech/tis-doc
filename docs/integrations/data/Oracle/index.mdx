---
title: Oracle
date: 2025-03-12
type: book
sidebar_position: 1
---

import Link from '/src/components/Link';
import Figure from '/src/components/Figure';
import BZhan from '/src/components/BZhan';
import PluginFields from '/src/components/PluginFields';

## 数据源配置

<Figure img={require('./datasource.png')}/>

* **配置项说明:** 

<PluginFields>

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. 服务节点

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		服务器节点连接地址，可以为IP或者域名

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1521
	* **说明:** 		无

4. 连接方式

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** SID
	* **说明:** 

		连接方式选择，[Oracle SIDs vs. Oracle SERVICE NAMES](https://www.stechies.com/difference-between-oracle-sids-and-oracle-service-names/)

	* **可选项说明:** 可选`SID`,`ServiceName`以下是详细说明：
		* SID

			<Figure img={require('./datasource_connEntity_SID.png')}/>

			* **配置项说明:** 

			1. SID

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** xe
				* **说明:** 		无

		* ServiceName

			<Figure img={require('./datasource_connEntity_ServiceName.png')}/>

			* **配置项说明:** 

			1. serviceName

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** 无
				* **说明:** 

					从 Oracle 8i 开始，Oracle 已经引入了 Service Name 的概念以支持数据库的集群 (RAC) 部署，一个 Service Name 可作为一个数据库的逻辑概念，统一对该数据库不同的 SID 实例的连接。

					以服务名方式连接方式 (即 port 和 dbname 中间使用 “ / ” 分隔开)，即：

					"jdbc:oracle:thin:@" + hostname + ":" + port + **"/"** + dbname

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** system
	* **说明:** 		无

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

7. 包含授权

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		Oracle系统会向用户授权其他用户名下的表
		
		* 如选择`on`可以包含系统授权的其他用户名下的表
		
		* 如选择`off`则只包含用户名下的表

	* **可选项说明:** 可选`on`以下是详细说明：
		* on

			<Figure img={require('./datasource_allAuthorized_on.png')}/>

			* **配置项说明:** 

			1. Schema

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** 无
				* **说明:** 

					可以只包含某一个模式（Schema）下的表，[Oracle模式对象schema的介绍](https://www.modb.pro/db/508147)

					可以不填，但当选中的表在多个授权Schema中出现时，TIS会报异常

			2. 去除保留Schema

				* **类型:** 单选
				* **必须:** 是
				* **默认值:** true
				* **说明:** 		过滤掉系统保留Schema，如："ANONYMOUS", "APEX_030200", "APEX_PUBLIC_USER", "APPQOSSYS", "BI", "CTXSYS", "DBSNMP", "DIP", "EXFSYS", "FLOWS_FILES", "HR", "IX"等

8. 所在时区

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** default
	* **说明:** 		设置服务端所在时区，有两种输入方式：1. default 从下拉框中选择，2. customize：用户手动输入时区编码

	* **可选项说明:** 可选`customize`,`default`以下是详细说明：
		* customize

			<Figure img={require('./datasource_timeZone_customize.png')}/>

			* **配置项说明:** 

			1. 时区编码

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** 无
				* **说明:** 		设置服务端所在时区编码

		* default

			<Figure img={require('./datasource_timeZone_default.png')}/>

			* **配置项说明:** 

			1. 时区编码

				* **类型:** 单选
				* **必须:** 是
				* **默认值:** com.qlangtech.tis.plugin.timezone.TISTimeZone.dftZoneId()
				* **说明:** 		选择服务端所在时区


</PluginFields>

## 批量读

<Figure img={require('./dataxReader.png')}/>

* **配置项说明:** 

<PluginFields>

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** false
	* **说明:** 		描述：OracleReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。

3. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		描述：控制写入数据的时间格式，时区等的配置，如果表中有时间字段，配置该值以明确告知写入 oracle 的时间格式。通常配置的参数为：NLS_DATE_FORMAT,NLS_TIME_FORMAT。其配置的值为 json 格式，例如：[
		              "alter session set NLS_DATE_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set NLS_TIMESTAMP_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set NLS_TIMESTAMP_TZ_FORMAT='yyyy-mm-dd hh24:mi:ss'",
		              "alter session set TIME_ZONE='US/Pacific'"
		            ]

4. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。

5. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXOracleReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误


</PluginFields>

## 批量写

<Figure img={require('./dataxWriter.png')}/>

* **配置项说明:** 

<PluginFields>

1. 目标数据库

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. session

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性 

5. 自动建表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

	* **可选项说明:** 可选`off`,`on`以下是详细说明：
		* off

			<Figure img={require('./dataxWriter_autoCreateTable_off.png')}/>

			* **配置项说明:** 

			1. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

		* on

			<Figure img={require('./dataxWriter_autoCreateTable_on.png')}/>

			* **配置项说明:** 

			1. 添加列注释

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** on
				* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

			2. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

6. batchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 1000
	* **说明:** 

		* 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

7. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataXOracleWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误


</PluginFields>

## 实时读

<Figure img={require('./mq.png')}/>

* **配置项说明:** 

<PluginFields>

1. startupOptions

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** latest
	* **说明:** 

		Optional startup mode for Oracle CDC consumer, valid enumerations are "initial" and "latest-offset". Please see Startup Reading Positionsection for more detailed information.
		
		参数详细请参考：[https://ververica.github.io/flink-cdc-connectors/master/content/connectors/oracle-cdc.html#connector-options](https://ververica.github.io/flink-cdc-connectors/master/content/connectors/oracle-cdc.html#connector-options)
		，[https://debezium.io/documentation/reference/1.5/connectors/oracle.html#oracle-connector-properties](https://debezium.io/documentation/reference/1.5/connectors/oracle.html#oracle-connector-properties)
		
		* `Initial`:
		  Performs an initial snapshot on the monitored database tables upon first startup, and continue to read the latest binlog.
		
		* `Latest`:
		 Never to perform a snapshot on the monitored database tables upon first startup, just read from the change since the connector was started.
		
		 **Note**: the mechanism of `scan.startup.mode` option relying on Debezium’s `snapshot.mode` configuration. So please do not use them together. 
		 If you specific both `scan.startup.mode` and `debezium.snapshot.mode` options in the table DDL, it may make `scan.startup.mode` doesn’t work.

2. Log Mining Strategy

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** redo_log_catalog
	* **说明:** 

		There are strategies: Online catalog with faster mining but no captured DDL. Another - with data dictionary loaded into REDO LOG files

3. Supports mining LOB fields and operations

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 

		When set to `false`, the default, LOB fields will not be captured nor emitted. When set to `true`, the connector will capture LOB fields and emit changes for those fields like any other column type.

4. Poll interval (ms)

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 500
	* **说明:** 

		Time to wait for new change events to appear after receiving no events, given in milliseconds. Defaults to 500 ms.

5. Event deserialization failure handling

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** fail
	* **说明:** 

		Specify how failures during processing of events (i.e. when encountering a corrupted event) should be handled, including:'fail' (the default) an exception indicating the problematic event and its position is raised, causing the connector to be stopped; 'warn' the problematic event and its position will be logged and the event will be skipped;'ignore' the problematic event will be skipped.

6. 过滤

	* **类型:** 单选
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 		可以将数据流中将某一种事件类型的事件过滤掉，有以下几种类型可以选择：INSERT, UPDATE_BEFORE, UPDATE_AFTER, DELETE

7. BinLog独立监听

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		无


</PluginFields>

## 实时写

<Figure img={require('./sinkFactory.png')}/>

* **配置项说明:** 

<PluginFields>

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** insert
	* **说明:** 

		控制写入数据到目标表采用 `insert into` 或者 `replace into` 或者 `ON DUPLICATE KEY UPDATE` 语句

3. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

	* **可选项说明:** 可选`SQL`,`StreamAPI`以下是详细说明：
		* SQL

		* StreamAPI

4. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

5. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

6. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度


</PluginFields>



