---
title: Doris
date: 2025-03-12
type: book
sidebar_position: 1
---

import Link from '/src/components/Link';
import Figure from '/src/components/Figure';
import BZhan from '/src/components/BZhan';
import PluginFields from '/src/components/PluginFields';

## 数据源配置

<Figure img={require('./datasource.png')}/>

* **配置项说明:** 

<PluginFields>

1. 实例ID

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		数据源实例名称，请起一个有意义且唯一的名称

2. host

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		目标数据库的 JDBC 连接信息，用于执行preSql及postSql

3. 端口

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 9030
	* **说明:** 		无

4. 数据库名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Doris表的数据库名称

5. 用户名

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** root
	* **说明:** 		Doris数据库的用户名

6. 密码

	* **类型:** 密码
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		Doris数据库的密码

7. loadUrl

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** []
	* **说明:** 

		Doris FE的地址用于Streamload，可以为多个fe地址，fe_ip:fe_http_port
		样例：
		
		```json
		["172.28.17.100:8030", "172.28.17.100:8030"]
		```


</PluginFields>

## 批量读

<Figure img={require('./dataxReader.png')}/>

* **配置项说明:** 

<PluginFields>

1. 数据库名

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. splitPk

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** false
	* **说明:** 		进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。
		推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。
		 目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！
		 如果splitPk不填写，包括不提供splitPk或者splitPk值为空，DataX视作使用单通道同步该表数据。

3. fetchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 2000
	* **说明:** 		执行数据批量导出时单次从数据库中提取记录条数，可以有效减少网络IO次数，提升导出效率。切忌不能设置太大以免OOM发生

4. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.DataxMySQLReader.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误


</PluginFields>

## 批量写

<Figure img={require('./dataxWriter.png')}/>

* **配置项说明:** 

<PluginFields>

1. 目标数据库

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** 无
	* **说明:** 		无

2. preSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 `@table` 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, ... datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：`"preSql":["delete from 表名"]`，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称

3. postSql

	* **类型:** 富文本
	* **必须:** 否
	* **默认值:** 无
	* **说明:** 

		写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）

4. 自动建表

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** on
	* **说明:** 

		解析Reader的元数据，自动生成Writer create table DDL语句，有三种选择：
		* `off`：关闭自动生成及同步目标端建表DDL语句，当目标端表实例已经存在可选择此选项。
		* `default`：打开动生成及自动执行目标端建表DDL语句，执行任务状态由程序自动控制毋需人为干涉。
		* `customized`：用户可自定义设置`自动执行目标端建表DDL语句逻辑`，如：是否需要生成列注释等。

	* **可选项说明:** 可选`off`,`on`以下是详细说明：
		* off

			<Figure img={require('./dataxWriter_autoCreateTable_off.png')}/>

			* **配置项说明:** 

			1. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

		* on

			<Figure img={require('./dataxWriter_autoCreateTable_on.png')}/>

			* **配置项说明:** 

			1. 添加列注释

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** on
				* **说明:** 		在建表DDL上添加列注释，需要依赖源端表列是否定义注释，如源端列上没有列注释，则目标端建表列DDL上也没有列注释

			2. 建表模型

				* **类型:** 单行文本
				* **必须:** 是
				* **默认值:** Unique
				* **说明:** 

					TIS可以帮助用户自动生成Doris端的建表DDL语句，如Doris中已存在对应的表可选择`Off`,如需要生成可以选择`Unique`和`Duplicate`之一，如需要使用`Aggregate`模型，由于Agg模型需要设置非聚合列的聚合函数，系统无法预知。
					可先选择`Unique`和`Duplicate`任意一种，待到DDL生成之后，手动在DDL之上进行修改。

					Doris 支持三种数据模型：

					1. Aggregate
					2. Unique
					3. Duplicate

					[数据模型详细](https://doris.apache.org/docs/table-design/data-model/overview)

			3. 副本数

				* **类型:** 整型数字
				* **必须:** 是
				* **默认值:** 1
				* **说明:** 

					设置Doris create table脚本中的副本数目：
					```sql
					CREATE TABLE `test`
					(
					    `id`      VARCHAR(96) NOT NULL,
					)
					 ENGINE=olap
					UNIQUE KEY(`id`)
					PROPERTIES("replication_num" = "1"  )
					```

			4. 分桶数

				* **类型:** 整型数字
				* **必须:** 是
				* **默认值:** 10
				* **说明:** 

					表Bucket的作用主要有以下几点：

					1. 数据分布：Bucket可以帮助数据在集群中更均匀地分布，提高数据的可靠性和容错性。
					2. 加快数据查询速度：通过对数据进行分桶，查询时可以只扫描涉及的Bucket，减少扫描的数据量，从而加快查询速度。
					3. 数据归档：Bucket可以用于数据的归档管理，将不再更新的数据移动到较为冷的Bucket中。
					4. 数据安全：Bucket也可以用于数据备份，一般会有多个Bucket副本以防止数据丢失。

					创建带Bucket的表的示例SQL语句如下：
					```sql
					CREATE TABLE `test`
					(
					    `id`      VARCHAR(96) NOT NULL,
					)
					 ENGINE=olap
					UNIQUE KEY(`id`)
					BUCKETS 16
					PROPERTIES("replication_num" = "1"  )
					```

			5. 别名前缀

				* **类型:** 单行文本
				* **必须:** 否
				* **默认值:** 无
				* **说明:** 		统一为目标表添加前缀，例如在构建分层数仓用于为ods层目标表统一添加前缀,例如：`ods_erp_`

5. loadProps

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter.getDftLoadProps()
	* **说明:** 

		StreamLoad 的请求参数,默认传入的数据均会被转为字符串，并以 **\t** 作为列分隔符，**\n** 作为行分隔符，组成csv文件进行 [StreamLoad导入参数说明](http://doris.apache.org/master/zh-CN/administrator-guide/load-data/stream-load-manual.html#%E5%AF%BC%E5%85%A5%E4%BB%BB%E5%8A%A1%E5%8F%82%E6%95%B0)。 如需更改列分隔符， 则正确配置 loadProps 即可：
		
		```json
		 {
		  "column_separator": "\\x01",
		  "line_delimiter": "\\x02"
		}
		```

6. maxBatchRows

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 10000
	* **说明:** 

		- 描述：单次StreamLoad导入的最大行数
		- 必选：否
		- 默认值：10000 (1W)

7. maxBatchSize

	* **类型:** 整型数字
	* **必须:** 否
	* **默认值:** 104857600
	* **说明:** 

		- 描述：单次StreamLoad导入的最大字节数。
		- 必选：否
		- 默认值：104857600 (100M)
		
		
		
		
		 * 描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。

8. 配置模版

	* **类型:** 富文本
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugin.datax.doris.DataXDorisWriter.getDftTemplate()
	* **说明:** 		无特殊情况请不要修改模版内容，避免不必要的错误


</PluginFields>

## 实时写

<Figure img={require('./sinkFactory.png')}/>

* **配置项说明:** 

<PluginFields>

1. semantic

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** at-least-once
	* **说明:** 

		**描述：** sink 端是否支持二阶段提交
		
		**注意：**
		    如果此参数为空，默认不开启二阶段提交，即 sink 端不支持 exactly_once 语义；
		    当前只支持 exactly-once 和 at-least-once

2. writeMode

	* **类型:** 单选
	* **必须:** 是
	* **默认值:** insert
	* **说明:** 

		控制写入数据到目标表采用 `insert into` 或者 `replace into` 或者 `ON DUPLICATE KEY UPDATE` 语句

3. 脚本类型

	* **类型:** 单行文本
	* **必须:** 是
	* **默认值:** StreamAPI
	* **说明:** 

		TIS 为您自动生成 Flink Stream 脚本，现支持两种类型脚本：
		
		* `SQL`: **优点**逻辑清晰，便于用户自行修改执行逻辑
		* `Stream API`：**优点**基于系统更底层执行逻辑执行、轻量、高性能

	* **可选项说明:** 可选`SQL`,`StreamAPI`以下是详细说明：
		* SQL

		* StreamAPI

4. batchSize

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 5000
	* **说明:** 

		描述：一次性批量提交的记录数大小，该值可以极大减少 ChunJun 与数据库的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成 ChunJun 运行进程 OOM 情况

5. flushIntervalMills

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 10000
	* **说明:** 		"the flush interval mills, over this time, asynchronous threads will flush data. The default value is 10s.

6. parallelism

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** 1
	* **说明:** 		sink 并行度

7. connectTimeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftConnectTimeout()
	* **说明:** 		和服务端建立连接的超时时间，单位：ms

8. socketTimeout

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftSocketTimeout()
	* **说明:** 		从服务端读取数据的超时时间，单位：ms

9. retries

	* **类型:** 整型数字
	* **必须:** 是
	* **默认值:** com.qlangtech.tis.plugins.incr.flink.chunjun.doris.sink.ChunjunDorisCommon.dftRetries()
	* **说明:** 		从服务端读取数据失败最大重试次数


</PluginFields>



